---
title: "Training Your First AI Model"
description: "Get started with AI by quickly training your first image classifier AI model."
imageUrl: "/images/blog/training-your-first-ai-model/album-covers.webp"
dateWritten: "2024-02-22"
isDraft: false
tags:
  - Artificial Intelligence
---

<img alt="Album covers from vinyl records on display on shelves" src="/images/blog/training-your-first-ai-model/album-covers.webp" width="1500" height="991">

# Training Your First AI Model

> Note: If you ever get stuck while implementing the directions in this article, you can refer to [this finished Kaggle notebook](https://www.kaggle.com/code/thnate/first-ai-model) and [this finished Hugging Face space](https://huggingface.co/spaces/nwthomas/dogs-and-cats) for a solution.

## Start Your Engine

There's something magical that happens when you manage to get code to do what you want. The itch is almost universal among hackers and coders, and it's why they keep coming back again and again.

When I first got addicted to programming, I loved the fact I could write code that would do exactly what I wanted it to even while I was asleep. For instance, you're reading this and I'm doing something completely different. I love that.

With the recent boom in artificial intelligence, we can take this once step further and create code that will predict, classify, and generate content for us.

A great course you can use to learn about this is one by FastAI called [Practical Deep Learning for Coders](https://course.fast.ai/). I'll be summarizing the first few chapters in a condensced format here that should get you up off the ground with your first model trained and deployed for use in no time.

We'll be building an [image classifier](https://huggingface.co/docs/transformers/tasks/image_classification) in this article, which means you can upload an image to it and it will predict whether it's a certain animal, shape, car, or whatever you decide to build.

I'd encourage you to think about what you want to make. Do you want to make an image classifier for dogs and cats? Perhaps you want to make one for [different types of food](https://www.youtube.com/watch?v=ACmydtFDTGs)?

> "It is difficult to think of a major industry that AI will not transform. This includes healthcare, education, transportation, retail, communications, and agriculture. There are surprisingly clear paths for AI to make a big difference in all of these industries."
>
> \- Andrew Ng

## Get Yourself Some GPUs

The first thing we need to do is sign up for a Kaggle account so that you can have a server and temporary access to GPUs for training your model.

Kaggle is a site that, among other things, allows people like you to participate in competitions for data science/building models; it also will allow you to run code in "notebooks" (more on this in a second) and train models _on its site_ using GPU servers.

<img alt="The Kaggle homepage" src="/images/blog/training-your-first-ai-model/kaggle-homepage.webp" height="967" width="1600">

Go ahead and head over to [kaggle.com](https://www.kaggle.com) to create a free account. I'll be here when you get back.

Ready?

Awesome. Next, go ahead and hit the `Create` button (which you'll see on the lefthand side if you go to your profile) to create a new notebook. Once you do, you'll see a blank notebook page that looks like this:

<img alt="A blank new Kaggle notebook without any code in it" src="/images/blog/training-your-first-ai-model/new-kaggle-notebook.webp" height="968" width="1600">

Go ahead and give it a new title like "My First AI Model" or "First AI Model" for now.

Okay, let's take a break for a second and talk through what we've done. First off, what is a "notebook" and why do we need it?

What I'm calling a "notebook" is really a [Jupyter Notebook](https://jupyter.org). What are those you might ask? Jupyter Notebooks are web-based development environments for data science and machine learning.

In other words, they're the environment we're going to run code in to create our AI models!

Now that you have a new notebook, go ahead and write the following code blocks in it (using the `+ Code` button when hovering in the main page):

```bash
!pip install fastbook
```

```python
import fastbook
fastbook.setup_book()
```

This is what it should look like:

<img alt="The new Kaggle notebook with a few cells of code in it" src="/images/blog/training-your-first-ai-model/first-notebook-cells.webp" height="967" width="1600">

Each code block should have a ‚ñ∂Ô∏è play button on the lefthand side if you click on the code block itself. Go ahead and press it for each of these.

You'll see a lot of text spit out for the first code block, but it's just indicative that it's installing Python modules for us to use. `Fastbook` is a dependency that speeds up our development by quick-installing a lot of the dependencies we'll need. The second code block is initial setup.

Next, add (and run) another code block with the following Python code:

```python
from fastbook import *
from fastai.vision.widgets import *
```

`fastai` is a package developed by the company [FastAI](https://www.fast.ai/) as a wrapper around [PyTorch](https://pytorch.org/) with lots of sane defaults so that you and I can get to hacking.

This is what it should look like once you're done:

<img alt="Final initial setup code cell in Kaggle notebook" src="/images/blog/training-your-first-ai-model/finished-initial-setup.webp" height="967" width="1600">

Good job üî•

Now it's time to download some real data so that we can train our model!

> "I imagine a world in which AI is going to make us work more productively, live longer, and have cleaner energy."
>
> \- Fei-Fei Li

## Download Your Data

So far, we've only really been concerned with setup. But in this section, we're going to download the data we'll need to train our AI model!

Remember earlier when I encouraged you to think of what kind of image classifier you were wanting to train? Well, it's time to use what you've decided on and jump in with both feet.

Go ahead and write the following code in a new code block (replacing `"dogs"` with whatever you want your model to predict):

```python
results = search_images_ddg("dogs")
len(results)
```

It should look like this:

<img alt="DuckDuckGo initial search in code block" src="/images/blog/training-your-first-ai-model/duck-duck-go-initial-search.webp" height="967" width="1600">

Once you run that, it should say something like `200` undernearth your code block. This is indicative of the number of results that were found matching your search!

Next, go ahead and add the following two code blocks and run them both:

```python
destination = 'images/dogs.jpg'
download_url(results[0], destination)
```

```python
image = Image.open(destination)
image.to_thumb(128,128)
```

It should look like this:

<img alt="Sampling image data from DuckDuckGo" src="/images/blog/training-your-first-ai-model/sampling-image-data.webp" height="967" width="1600">

Nice. This is always a good idea to do as we're effectively sampling the image data to make sure we're pulling in something that we'd expect from our search query term.

Next, we need to setup all our queries. These will be other categories for images to fall into. I'm going to search for `"dogs"` and `"cats"` as well to keep with the whole animal theme:

```python
animal_types = "dogs", "cats"
path = Path("animals")
```

This declares a list of annimals (or whatever you decide to train your model on) that our image classifier will place images into.

Finally, we've defined an `animals` path which will be our root directory where a separate folder for each `animal_types` string will be created in to download its associated images into.

Next, go ahead and make and run this code block (replacing `"animals"` with whatever the parent category is for the type of images you're downloading):

```python
if not path.exists():
    path.mkdir()

for o in animal_types:
    dest = (path/o)
    dest.mkdir(exist_ok=True)
    results = search_images_ddg(o)
    download_images(dest, urls=results)
```

This will take quite a bit of time to run. You're using DuckDuckGo to download images. You can actually see them downloading in real time if you open up the right sidebar (with the array on the bottom-right part of your screen) and then dig down to the files here:

<img alt="Downloading images from DuckDuckGo" src="/images/blog/training-your-first-ai-model/downloading-images.webp" height="967" width="1600">

Once this code block finishes running, you now have your dataset for training your model!

Before using this data, we should remove any errored image paths that failed to download.

Go ahead and paste this code into a code block and then run it:

```python
fns = get_image_files(path)
failed = verify_images(fns)
len(failed)
```

Here's what it looked like for me when I ran it:

<img alt="Checking how many image paths have errored out while downloading from DuckDuckGo" src="/images/blog/training-your-first-ai-model/errored-image-paths.webp" height="967" width="1600">

Go ahead and remove those by putting this code into a code block and running it:

> Note: This will unlink the errored images the first time you run it. If you run it a second time, it will error out as there aren't any image paths to remove anymore.

```python
failed.map(Path.unlink);
```

Next, we need to sample the data we've downloaded to make sure it's valid. In order to do that, we need to setup up some data loaders to manipulate our images.

Go ahead and jump into the next section to do that when you're ready.

> ‚ÄúSome people worry that artificial intelligence will make us feel inferior, but then, anybody in his right mind should have an inferiority complex every time he looks at a flower.‚Äù
>
> \- Alan Kay

## Setting Up Our Dataloaders

In order to manipulate our data, we're going to use a class exported from `fastai` called a `Dataloader`.

Go ahead and create (and, like always, run) this code block:

```python
animals = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,
    splitter=RandomSplitter(valid_pct=0.2, seed=42),
    get_y=parent_label,
    item_tfms=RandomResizedCrop(224, min_scale=0.5),
    batch_tfms=aug_transforms(),
)
```

Okay. What's going on here?

Good question.

First, we have this line

```python
dls = animals.dataloaders(path)
```

> Note: If you see an error while running this (like in my image below) about "'has_mps' is deprecated", disregard it.

Here's what this will looks like once you're done:

<img alt="Dataloaders all set up for training" src="/images/blog/training-your-first-ai-model/dataloaders.webp" height="967" width="1600">

Believe it or not, the hard part is done now. From here, we get to train our model!

Let's get the party started ü•≥

> "We can build a much brighter future where humans are relieved of menial work using AI capabilities."
>
> \- Andrew Ng

## Train Your New Model

In order to train our model, go ahead and put this code block in and run it (I'll explain what it's doing while it's running since it's going to take a while):

```python
learn = vision_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(4)
```

When you run this, it's going to kick off actually training your model.

First, we're defining a `vision_learner` (makes sense for an image classifier, right?) that takes in your new `dataloader` that you created in the last section.

It's also using a pre-trained model, `resnet18`, to speed up the process of training. Using pre-trained models as a jumping off point is an excellent strategy and one widely used in the industry.

Finally, we're telling the `vision_learner` how to define metrics for the training session. In our case, we're specifically using `error_rate`. We want to use the rate of errors of misclassified images to define our metrics.

After we set up our `vision_learner`, we will go ahead and call `fine_tune` on it and run it for `4` epochs. An epoch is an iteration round of training the model, analyzing the error rate, and learning from it.

Let's let this run for a bit. You should go make some coffee or tea. It could be a few minutes.

Done?

Okay. This is what it should look similar to (again, ignore the errors here if you have them):

<img alt="FastAI's visual_learner all done training a model" src="/images/blog/training-your-first-ai-model/trained-model.webp" height="967" width="1600">

Nice. It's time to export the model and fire it up for use!

> "AI will probably most likely lead to the end of the world, but in the meantime, there'll be great companies."
>
> \- Sam Altman

## Export Your Model

It turns out that it's actually quite easy to export your model (called a `.pkl` file).

Add this code block to your notebook:

```python
learn.export()
```

Run that, and you're ready to download the file!

Check out the files in the sidebar again. You should see an `export.pkl` file like this:

<img alt="An export-ready .pkl file in your Kaggle notebook" src="/images/blog/training-your-first-ai-model/export-ready-model.webp" height="967" width="1600">

If you hover over that, you should be able to click on three dots that open a menu where you can download the file.

Congrats. You've just exported a full AI model. Let's go ahead and figure out how to run it!

> "AI is neither good nor evil. It's a tool. It's a technology for us to use."
>
> \- Oren Etzioni

## Get a Live Model Using Hugging Face and Gradio

The final piece of the puzzle is to create a Hugging Face account and host your model there so you can interact with it (using the Hugging Face site).

First, go ahead and sign up for free account at [Hugging Face](https://huggingface.co).

Once you're done, create a new "Space" (for running your model) by going to the "Spaces" page and clicking "Create new Space" which should look like this:

<img alt="The Hugging Face homepage for Spaces" src="/images/blog/training-your-first-ai-model/hugging-face-spaces-page.webp" height="967" width="1600">

Got ahead and give your Space a name and use a license like MIT for it:

<img alt="Creating a new Hugging Space page" src="/images/blog/training-your-first-ai-model/hugging-face-new-space.webp" height="967" width="1600">

Select "Gradio" as the Space SDK and leave the other settings as-is before clicking "Create Space"!

Next, go ahead and clone down the Hugging Face repo you just created. The HTTPS or SSH cloning commands will be listed inside the page.

Once you've done that, add these files to your repo:

```python
# In an app.py file
import gradio as gr
from fastai.vision.all import *

learn = load_learner("export.pkl")

# Update these to whatever your categories were for training
categories = ("cats", "dogs")

def classify_image(img):
    """Takes in an image and classifies it using a model"""
    pred, idx, probs = learn.predict(img)
    return dict(zip(categories, map(float, probs)))

image = gr.Image()
label = gr.Label()

demo = gr.Interface(fn=classify_image, inputs=image, outputs=label)
demo.launch(inline=False)
```

```python
# In a requirements.txt file
fastai
```

Commit them and then push them up to the Space. Once it's done, refresh the Hugging Face Space; you should see something like this:

<img alt="The Hugging Face space building" src="/images/blog/training-your-first-ai-model/hugging-face-space-building.webp" height="967" width="1600">

Once it's done, the application will say that it's starting. This can take quite a bit of time, so be patient. Free tools aren't always the fastest.

However, you'll eventually see something much like this:

<img alt="The Hugging Face space build error" src="/images/blog/training-your-first-ai-model/hugging-face-space-build-error.webp" height="967" width="1600">

Oh no! What happened?

Don't worry. This was part of my plan. You see, trying to upload your `export.pkl` file with Git would have thrown an error becuase of how large the file is.

You should head to the "Files" tab and then choose the "Add file" and "Upload files" option here:

<img alt="The new Hugging Face space file upload process" src="/images/blog/training-your-first-ai-model/hugging-face-space-file-upload.webp" height="967" width="1600">

On the next page, you'll be able to directly upload and then commit your `export.pkl` file. Do that, and then wait. Once again, you'll be presented with a building page for your Hugging Face Space.

Once it's done, you should be presented with a beautiful UI for interacting with your model!

<img alt="Your finished Hugging Face Space" src="/images/blog/training-your-first-ai-model/hugging-face-finished-space.webp" height="967" width="1600">

Go ahead and upload an image for whatever category you trained your model on. I'm going to upload a dog picture. Check out this prediction:

<img alt="First Hugging Face prediction" src="/images/blog/training-your-first-ai-model/hugging-face-first-prediction.webp" height="967" width="1600">

Great job! You should be able to use your model now. Go back some steps and try experimenting with different models, uploading them here to interact with them once you're done training.

The sky's the limit for you now.

## Conclusion

There you go. You've trained a new model to do what you want _and_ learned how to deploy and interact with it.

From here, the sky is the limit. I'd _highly_ recommend you go check out FastAI's [Practical Deep Learning for Coders](https://course.fast.ai/) course if you want to learn more. This article covers roughly the first two lectures.

Feel free to shoot me a message on the contact form on this website with whatever you've created! I'd love to see it.

As always, thanks for reading.

Nathan ‚òï
